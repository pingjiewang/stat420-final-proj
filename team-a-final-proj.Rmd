---
title: "Building an Used Car Price Prediction Model for Germany eBay listings"
author: "Richa Gupta/Sandro Tanis/Ping Wang"
date: "Aug 07, 2020"
output:
  html_document:
    theme: readable
    toc: yes
  word_document:
    toc: yes
  pdf_document: default
course: STAT 420, Summer 2020
urlcolor: cyan
---

***

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
library(knitr)
opts_chunk$set(cache = TRUE, autodep = TRUE)
knitr::opts_chunk$set(fig.width=10) 
```


# 1. Introduction

The formation of our group hinged upon our interest in the automotive industry, as a result of that we have chosen this robust dataset because we wanted to have a better understanding about the used car market and this dataset had all of the components that we wanted to observe for this project.The dataset that I am using in this project was found on Kaggle, the well-known Machine Learning Competition website and it is about Used Car listings from eBay – Germany. 

The dataset we are using for this project was found on Kaggle, the well-known Machine Learning Competition website and it is about Used Car listings from eBay – Germany please see link here: https://www.kaggle.com/orgesleka/used-cars-database/home. 

* Data file contains approximately **370,000 observations** and **20 variables** that are scraped from used-car listing on Ebay-Kleinanzeigen (German). The high quantity and authenticity makes this dataset useful for an exploratory analysis.

* Below is the list of various variables associated with the dataset:
  * **name**: Name of the car
  * **abtest**: Indicates the A/B testing group used by ebay website team
  *	**seller**: Whether the seller is private or a dealer
  *	**offerType**: The type of listing
  * **price**: The price on the ad to sell the car.
  * **vehicleType**: The vehicle Type.
  * **yearOfRegistration**: The year in which year the car was first registered.
  * **gearbox**: The transmission type.
  * **powerPS**: The power of the car in PS.
  * **model**: The car model name.
  * **kilometer**: How many kilometers the car has driven.
  * **monthOfRegistration**: The month in which year the car was first registered.
  * **fuelType**: What type of fuel the car uses.
  * **brand**: The brand of the car.
  * **notRepairedDamage**: If the car has a damage which is not yet repaired.
  * **postalCode**: The postal code for the location of the vehicle.
  
* The dataset is very large, so we decided to clean it and reduce it further that would help us to do effective analysis. 
* We considered cars that were registered after the year 2000, so we can build a good model based on the last 20 years in the used auto industry in Germany. 
* We randomly sampled 100,000 records after our data cleaning process, and split half the data in our training dataset and test dataset which resulted in 50,000 records each for our model prediction. We used below variables for our final analysis. 
  * **price**: The price on the ad to sell the car.
  * **abtest**: Indicates the A/B testing group used by ebay website team
  * **vehicleType**: The vehicle Type.
  * **yearOfRegistration**: The year in which year the car was first registered.
  * **gearbox**: The transmission type.
  * **powerPS**: The power of the car in PS.
  * **kilometer**: How many kilometers the car has driven.
  * **fuelType**: What type of fuel the car uses.
  * **notRepairedDamage**: If the car has a damage which is not yet repaired.
 
This project focuses on finding a good model for predicting based on the statistical knowledge that we gained from the class. We tried to determine the relationship between different variables, between the chosen predictor variable and price. Furthermore, our goal is  to build a MLR model for used car price prediction where we use price as the response variable, the predictors will be selected from all remaining continuous numerical variables such as (PowerPs, Kilometer, yearRegistrations) and the other  categorical variables so we can make compare 2 different methods so we can arrive to the best model that will fit our prediction. We will also be using the leftover observations to validate our model performance trough examining our assumptions by using regression diagnostic testing. Other method that we will be using are collinearity to check for issues on model and dummy variables for categorical fields. Finally, additional methods such as: outlier diagnostics, polynomial regression, and transformations will be leveraged when needed to further analyze and prove that our final model is justified.

# 2. Methods

In this section, we will start with data cleaning steps to remove observations that seem unreasonable. We will then follow by steps to remove unwanted columns and creating datasets for training(model building) and testing. We will create one training dataset consists of 50,000 randomly sampled record, and likewise for the testing dataset. We will also examine continuous numeric predictors for any collinearity issues. 

With the training dataset, we will take methods to find a set of good candidate models. 

## 2.0 Data preparation

### 2.0.1 Loading necessary Libaries and the script file
```{r,warning=FALSE,message=FALSE}
library(dplyr)
library(readr)
library(lmtest)
library(MASS)
source("misc_functions.R")
```
The major libraries needed will be loaded from here to be able to be used throughout the document. This will include the libraries such as LMTEST to test linear regression model, read input from a csv files readr, and dplyr which enables us to manipulate the dataset.

### 2.0.2 Data loading
Loading the raw data from the CSV file:  
```{r,warning=FALSE,message=FALSE}
autos_raw <- read_csv("autos.csv")
attr(autos_raw, 'spec') <- NULL
attr(autos_raw, 'problems') <- NULL

str(autos_raw)
```


### 2.0.3 Data cleaning and unused columns removal

```{r}
autos=subset(autos_raw, price>500 & price<200000 & yearOfRegistration>=2000 & powerPS>0 & offerType=="Angebot" & seller=="privat")
columns_remove=c("postalCode","lastSeen","name","model","brand", "nrOfPictures","dateCreated","dateCrawled","monthOfRegistration","offerType","seller")   
columns_numeric = c("price","powerPS","yearOfRegistration","kilometer")
columns_factor = c("abtest","vehicleType","gearbox","fuelType","notRepairedDamage" )
autos=na.omit(autos)
autos = autos[, -which(names(autos) %in% columns_remove)]
```
Our data cleaning process involved removing not-so-useful variables such as postalCode, lastSeen, name etc.. and clean the data by removing NAs and other values that might be not of significance.

After loading the raw data, **autos_raw** we: 

- Removed data with $price < 0$ (because a car cannot be associated with $0 pricing)
- Keep only data with offerType="Angebot" and seller=="privat", (because 99% percent of the data is associated with these values) 
- Keep only data with YearOfRegistration>=2000, (to focus only on last 20 years worth of registered cars)
- Removed unused columns: `r columns_remove`, (for better analysis and predictions)
- Identify continous numeric columns : `r columns_numeric`, (to help with our methods)
- Identify factor columns : `r columns_factor`, (to help with our methods)

### 2.0.4 Checking collinearity on numberic variable
Taking a look at the continuous variables only - checking for collinearity

```{r}
#Checking colinear on numberic columns on 50,000 records sample
sample_size=50000
idx_sample=sample(1:nrow(autos),sample_size)
autos_sample= subset (autos[idx_sample,], select = columns_numeric) 
pairs(autos_sample,col="dodgerblue")
```
```{r}
round(cor(autos_sample), 2)
```

Based on the above Pair plot and the output of cor() function, we have determined there no significant collinearity issues. Therefore, we can proceed to include all continuous variables (except for Price) as model predictors.

### 2.0.5 Setup training and testing data

```{r}
#Setup data with 100,000 randomly sampled and all columns
training_size=50000
set.seed(20200807)
idx_train=sample(1:nrow(autos),training_size)
autos_train= autos[idx_train,]
autos_train[,columns_factor]=lapply(autos_train[,columns_factor], as.factor)
str(autos_train)

#test data
test_size=training_size
idx_remain = !(1:nrow(autos) %in% idx_train)
autos_remain = autos[idx_remain, ]
idx_test=sample(1:nrow(autos_remain),test_size)
autos_test= autos_remain[idx_test,]
autos_test[,columns_factor]=lapply(autos_test[,columns_factor], as.factor)
rm(autos_remain)
```

## 2.1 Method 1 - a straightforward but dump approach

In this first approach to finding a candidate model, we use an additive model using all available predictors as the starting model in BIC backward search. Once we have the chosen model, we will examine the LINE model assumptions using a fitted-verse-residual plot model and a Q-Q plot.

## 2.1.1 Start with an additive model using all predictors (numeric + factor)
```{r}

model1_start=lm(price~.,data=autos_train)
#size of staring model
length( coef(model1_start) )

```

## 2.1.2 Run a backward BIC search
```{r}
#Run BIC backward search
n=nrow(autos_train)
model1_bic = step(model1_start,k=log(n),trace = 0)
#size of selected model by backward BIC
length( coef(model1_bic) )
model1_bic
```

## 2.1.3 Check for violation of model assumptions
```{r}
diagnostics(model1_bic)

#Save this model as the first candidate model
model1_selected=model1_bic
```

Based on the plot results, we concluded this is not a good model as the Fitted Residuals and Q-Q Plots indicated some sort variable tranformations are needed.



## 2.1.4 Remove high influential points to see improvement in model assumption violations

```{r}
remove_high_influential_points_and_refit_model(model1_selected,autos_train)
```

Removing the high influential points (about 3% of observations) does improve the model a little. But it is still not ideal. We will save the model (model1_selected) as the first candidate model. In the result section, we will compare its performance with other candidate models. 

Because there seems to be a violation of the linearity assumption here, we will introduce response and predictor transformation in the next method.

## 2.2  Method 2 - With variable transformations

In this second approach to finding a good price prediction model, we will introduces variable transformations. We will take the following 2-phases approach:

- Phase 1 - Use the only continuous variables to determine the response transformation using Box-Cox and the predictor transformation using BIC backward search. 

- Phase 2 - Adding categorical variables to the model format obtained from Phase 1. 

### 2.2.1 - Phase 1: determine the best model formula format using only the continuous variables

#### 2.2.1.1 - Break data-set into subgroups by fixing factor variable values

To reduce the price variability due to different combinations of factor variable values, we will temporarily isolate a dataset for the analysis here in phase 1. Later, we will use the full training dataset in Phase 2 steps. To do this, we will use 'dplyr' package count() to group dataset by all factor variables. 

```{r}
#listing out all factor columns
columns_factor

autos_factor_groups=autos %>% count (abtest,vehicleType,gearbox,fuelType,notRepairedDamage)
autos_factor_groups=autos_factor_groups[order(autos_factor_groups$n,decreasing = TRUE),]

#structure of autos_factor_groups
head(autos_factor_groups)

#Total number of groups
nrow(autos_factor_groups)

#Number of groups with more than 300 records
sum(autos_factor_groups$n>300)
```

Next, we will break our dataset into groups, we will choose group #2 to isolate a dataset by filtering from the main dataset.

#### 2.2.1.2 - isolate a subset data (autos_1) for Phase 1 
```{r}
#choose group
selected_group_idx=2
group1=autos_factor_groups[selected_group_idx, ]
(group1.size = group1$n)
group1=subset(group1, select = -c(n) )

#get the records for the selected group
autos_1=autos
cols=names(group1)
for (i in 1:ncol(group1)){
  idx = autos_1[,cols[i]]==group1[[i]]
  autos_1=autos_1[idx,]
}
autos_1=subset(autos_1, select = columns_numeric )

```

Next, we will use the newly isolated dataset, **autos_1** to help better finding a model formula form for continuous variables

#### 2.2.1.3 - Try an additive model using all continous variables

We will start with fitting an additive model using all continous variables.

```{r}
par(mfrow=c(1,2))
model2_add = lm(price ~ powerPS +yearOfRegistration+kilometer, data = autos_1)
diagnostics(model2_add)
```

The plots indicates signifant voiloation of equal variance, normality assumption. We will try Box-Cox transformation on Price to improve linearity assumption next.


#### 2.2.1.4 - Try Box-Cox tranformation on the selected group


```{r}
par(mfrow=c(1,1))
boxcox_input_formula= as.formula ( as.character(model2_add$call[2]) )
out=boxcox(model2_add, plotit = TRUE, lambda = seq(-0.5, 1.0, by = 0.05))
( lambda=out$x[which.max(out$y)] )
model2_add_cox = lm( ((price^lambda-1)/lambda) ~ powerPS +yearOfRegistration , data = autos_1 )
diagnostics(model2_add_cox)
```

After the Box-Cox transformation (with $\lambda=`r lambda`$), the plots look better, but it seems additional predictor transformation might help.

#### 2.2.1.5 - finding predictor tranformation via backward BIC search

To determine the best predictor transformation, we will use a backward BIC search. We will use a starting model that includes first-order, second-order, and log() terms for all three continuous variables. The resulting BIC search will tell us the best formula format.


```{r}
# starting with log and 2nd order terms for all predictors
model2a_bic_start=lm( (price^lambda-1)/lambda ~ powerPS+I(log(powerPS)) + I(powerPS^2)
                        +yearOfRegistration + I(log(yearOfRegistration)) + I(yearOfRegistration^2) 
                        +kilometer + I(log(kilometer)) + I(kilometer^2)
                      , data = autos_1 )
  



model2a_bic = step(model2a_bic_start,trace=0)
diagnostics(model2a_bic)
summary(model2a_bic)

#Save model2a for later steps
model2a=model2a_bic
formula_str=as.character(model2a$call[2])
```

The best formula format determined by backward BIC search(using only continuous variables) is:

- **`r formula_str`**

Next, we will use this formula form plus categorical variables for finding model in Phase 2.

### 2.2.2 - Phase 2: adding categorical variables to the Phase-1 model formula

From Phase 1, we determine the best model based on all continous variables only(ie. without categorial column) is:  
- `r formula_str`  
- Where we will determine the new $\lambda$ value next step, based on entire training dataset

Next, we will add all factor variables to the formula format we obtained from Phase 1 as the starting model in backward BIC search.

#### 2.2.2.0 - Run box-cox tranformation on all training data
Because the preious $\lambda$ value was based on a smaller isolated dataset, we will need to re-determine $\lambda$ value by fitting established model form on all training data.

- **Formula format determined from Phase 1**: `r formula_str`
  
```{r}

par(mfrow=c(1,1))

model_2a_all= lm (price ~ powerPS + I(log(powerPS)) + I(powerPS^2) + I(log(yearOfRegistration)) + kilometer + I(log(kilometer)),data=autos_train)

diagnostics(model_2a_all)

par(mfrow=c(1,1))
out=boxcox(model_2a_all, plotit = TRUE, lambda = seq(-0.5, 1.0, by = 0.05))
( lambda=out$x[which.max(out$y)] )

```
  
#### 2.2.2.1 Searching for a good model using backward BIC with model format from Phase 1   
Here, we will find a useful model with a BIC search. We will start a backward search with the model, including all predictors(numeric plus categorial), and those transformation terms that we obtained from Phase 1.

```{r}
par(mfrow=c(1,1))
#model2_start = lm( ((price^lambda - 1)/lambda) ~ .-vehicleType +  I(powerPS^2), data=autos_train ) 
model2_start = lm( ((price^lambda - 1)/lambda) ~ .+I(log(powerPS)) + I(powerPS^2) + I(log(yearOfRegistration)) + I(log(kilometer)), data=autos_train ) 

n=nrow(autos_train)
model2_selected_bic = step(model2_start,k=log(n),trace=0)
summary(model2_selected_bic)

diagnostics(model2_selected_bic)

model2_selected=model2_selected_bic

model2_selected_bic$call[2]
```

We saved the chosen BIC model, model2_selected as our second candidate model, which will be tested in the result section.

#### 2.2.2.2 Verify regression significant with ANOVA test on high p-Value betas(vehicleType and fuelType)

The model summary coefficient(from the last step) shows some parameters with high p-Value, which is an indication of non-significance. Hence, we will conduct ANOVA tests to verify.

First, we will try to see if "vehicleType" categorical variable is significant.

```{r}
#-vehicleType
null_model_str = paste (as.character(model2_selected_bic$call[2]), "-vehicleType")
model_null= lm(null_model_str, data = autos_train)
anova(model_null,model2_selected_bic)
```

The lower p-value assures the "vehicleType" is significant. So we keep it in the model. 

Likewise, we will try ANOVA test on "fuelType"

```{r}
#-fuelType
null_model_str = paste (as.character(model2_selected_bic$call[2]), "-fuelType")
model_null= lm(null_model_str, data = autos_train)
anova(model_null,model2_selected_bic)
```

Again,The lower p-value assures the "fuelType" is aslo significant. So we keep it in the model as well. 



####  2.2.2.3 Remove high influential observations and refit the Phase 2 model

```{r}
fix_model=remove_high_influential_points_and_refit_model(model2_selected_bic, autos_train)
fix_model

```

After removing all high influential observations, The resulting model shows a very lovely Fitted-Residual and Normal Q-Q plot. The high influential observations account for `r fix_model$removed.fraction*100`% of the entire training dataset. The output indicates the chosen model is a good one for the majority(`r 100-fix_model$removed.fraction*100`%) of the training data. 

## 2.3  Method 3 - adding interaction terms on top of method 2 model (Did not yield a new candidate model)

In this method, we will start with the chosen model from Method 2 and see if adding two-way interaction terms will result in a new candidate model, using backward BIC search.

```{r}
library(tictoc)
lambda
#Please note that a two-way interaction term (.^2) is used.
model3a_bic_start=lm( (price^lambda-1)/lambda ~ .^2
                      + I(log(powerPS)) + I(powerPS^2)
                      + I(log(yearOfRegistration)) + I(yearOfRegistration^2) 
                      + I(log(kilometer)) + I(kilometer^2)
                      , data = autos_1 )

model3a_bic = step(model2a_bic_start,trace=0)
diagnostics(model3a_bic)
summary(model3a_bic)

```

The resulting model here is the same as the one found in Method 2 Phase 1 (model2a_bic). Therefore, **we won't be able to find a new model** with in this method So, we will stop here.

# 3. Results

*Method 1* resulted in *additive model* which has price as the response with predictors as vehicleType, yearOfRegistration, gearbox, powerPS, kilometer, fuelType and notRepairedDamage.
    
*Method 2* resulted in *interaction model* where response variable price was transformed using boxcox transformation. Predictors used in the model include vehicleType, gearbox, powerPS, kilometer, fuelType, notRepairedDamage and yearOfRegistration. Predictors powerPS, yearOfRegistration and kilometer are log transformed.

We use *train and test RMSEs* to evaluate the chosen 2 models. Please note that since the interaction model response was transformed, we will have to change it back to its unit of measure by applying reverse transformation. 

```{r}
#mod1 RMSEs
Train_RMSE_mod1 = calc_rmse(autos_train$price, predict(model1_selected, autos_train, type = 'response'))
Test_RMSE_mod1 =  calc_rmse(autos_test$price, predict(model1_selected, autos_test,type = 'response'))

#mod2 RMSEs
Train_RMSE_mod2 = calc_rmse(autos_train$price, (predict(model2_selected, newdata = autos_train, type ='response')*lambda+1)^(1/lambda))
Test_RMSE_mod2 = calc_rmse(autos_test$price, (predict(model2_selected, newdata = autos_test, type ='response')*lambda+1)^(1/lambda))

# calculate all train errors
train_error = c(Train_RMSE_mod1, Train_RMSE_mod2)

# calculate all test errors
test_error = c(Test_RMSE_mod1, Test_RMSE_mod2)

auto_models = c("Additive model", "Transformation model")
auto_results = data.frame(auto_models, train_error, test_error)
colnames(auto_results) = c("Model", "Train RMSE", "Test RMSE")
knitr::kable(auto_results)
```
As seen from the above table, the transformation model has a lower test and train RMSEs, suggesting it to be a better model.

We will now compare the 2 models using coefficient of determination R2, adjusted R2:

```{r}
summary(model1_selected)
summary(model1_selected)$adj.r.squared
```

Since this is an additive model, several interpretations can be made from the summary results. As the year of registration increase by one, the price increases by 900 euros. As the kilometers driven by the car increases by one, the price decreases slightly by 0.3829 euros, which sounds correct.  

```{r}
#Calculating R2 for additive model
#Total sum of squares
SST = sum((autos_train$price - mean(autos_train$price))^2)

#Residual sum of squares
fitted = predict(model1_selected, newdata = autos_train)
SSReg = sum((fitted - mean(autos_train$price))^2)
(R2 = SSReg / SST)
```


```{r}
summary(model2_selected)
summary(model2_selected)$adj.r.squared
```

```{r}
#Calculating R2 for transformation model
fitted = (predict(model2_selected, newdata = autos_train)*lambda+1)^(1/lambda)

#Residual sum of squares
SSReg = sum((fitted - mean(autos_train$price))^2)

(R2 = SSReg / SST)
```

|                      | R2     | Adjusted R2 |
|----------------------|--------|-------------|
| Additive model       | 0.5454 | 0.5452      |
| Transformation model | 0.6202 | 0.8248      |

Transformation model has a higher R2 than the Additive model, however that can be the case because transformation is a bigger model with 21 coefficients, compared to additive model that has 19 coefficients. But by checking adjusted R2, we can confirm that transformation model indeed is a preferred model.

# 4. Discussion

Using a dataset from Kaggle that contains German eBay used car ads, we started by doing some of data cleaning to remove unreasonable data from the dataset. We refrained from doing any translations or conversions of data from German language to English due to our limited time for this project. Furthermore, We created one training dataset consists of 50,000 randomly sampled record and another testing the same size. 

Moreover, we tried three different modeling approach and generated 2 candidate model. Below are the following methods that we have explored:

In *method 1*, we tried fitting an Additive Model with all variables. Then using BIC backward search, found the model best fitted where predictors chosen were vehicleType, yearOfRegistration, gearbox, powerPS, kilometer, fuelType and notRepairedDamage. This model clearly violated the linearity and constant variance assumption and the normality assumption is also violated as seen from Q-Q plot. With this method we generate a candidate model which we referred as to the Additive Model.

In *method 2*, We introduced variable transformations with the following 2-phases approach:

- Phase 1 - Use the only continuous variables to determine the response transformation using Box-Cox and the predictor transformation using BIC backward search. 

- Phase 2 - Adding categorical variables to the model format obtained from Phase 1. 

The chosen model in Method 2 uses price as transformed using Box-Cox transformation with the following predictors: vehicleType, yearOfRegistration, gearbox, powerPS, kilometer, fuelType, notRepairedDamage as predictors. It also included non-linear terms of log(powerPS), powerPS^2, log(yearOfRegistration), and log(kilometer). We referred to this model as the Transformation Model.

In *method 3*,  We started with the chosen model from Method 2 and   added two-way interaction terms in order to find a new candidate model, using backward BIC search. However, the Interaction method that we have tried, yielded the same results in method 2.


Results section shows the comparison between additive and transformation models by calculating their test and train RMSEs. Based on the result for both models, the RMSE is only slightly higher than the training RMSE which indicates that we do not have overfitting issue with the model. The tranformation model test and train RMSEs were 25% to 30% lower than the additive model showing that the transformation model is our preferred model. Furthermore, the second model is smaller in size. 

# 5. Appendix

Below file lists all the functions being used in the methods section:

```{r engine='bash', comment=''}
cat -n misc_functions.R
```




