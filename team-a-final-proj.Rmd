---
title: "Building an Used Car Price Prediction Model for Germany eBay listings"
author: "Richa Gupta/Sandro Tanis/Ping Wang"
date: "Aug 07, 2020"
output:
  html_document:
    theme: readable
    toc: yes
  word_document:
    toc: yes
  pdf_document: default
course: STAT 420, Summer 2020
urlcolor: cyan
---

***

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
library(knitr)
opts_chunk$set(cache = TRUE, autodep = TRUE)
```


# 1. Introduction

This is the introduction...
todo: (Sandro)

# 2. Methods

## 2.0 Data preparation

```{r,warning=FALSE,message=FALSE}
library(dplyr)
library(readr)
library(lmtest)
```


### Data loading
Loading the raw data from the CSV file:  
```{r,warning=FALSE,message=FALSE}
autos_raw <- read_csv("autos.csv")
attr(autos_raw, 'spec') <- NULL
attr(autos_raw, 'problems') <- NULL

str(autos_raw)
```


### Data cleaning and unused columns removal

```{r}
autos=subset(autos_raw, price>0 & yearOfRegistration>=2000 & offerType=="Angebot" & seller=="privat")
columns_remove=c("postalCode","lastSeen","name", "nrOfPictures","dateCreated","dateCrawled","monthOfRegistration","offerType","seller")   
columns_numeric = c("price","powerPS", "kilometer","yearOfRegistration")
columns_factor = c("abtest","vehicleType","gearbox","model","brand","fuelType","notRepairedDamage" )
autos=na.omit(autos)
autos = autos[, -which(names(autos) %in% columns_remove)]
```


After loading the raw data, **autos_raw** we: 

- Removed data with $price < 0$ 
- Keep only data with offerType="Angebot" and seller=="privat". **todo: why?**
- Keep only data with YearOfRegistration>=2000,  **todo: why?**
- Removed unused columns: `r columns_remove`,  **todo: why?**
- Indentify continous numeric columns : `r columns_numeric`
- Indentify factor columns : `r columns_factor`

```{r}
#final data format
str(autos)
```

Taking a look at the continous varialbes only - checking for colinearity

```{r}
#Checking colinear on numberic columns on 2000 records sample
sample_size=2000
idx_sample=sample(1:nrow(autos),sample_size)
autos_sample= subset (autos[idx_sample,], select = columns_numeric) 
pairs(autos_sample,col="dodgerblue")
```

todo: checking colinear with cor()...

todo: describe observations.

## 2.1 Method 1 - a straightforward but dump approach

```{r}
#Setup data with 2000 randomly sampled and all columns
sample_size=2000
idx_sample=sample(1:nrow(autos),sample_size)
autos_train= autos[idx_sample,]
model1_start=lm(price~.,data=autos_train)
#size of staring model
length( coef(model1_start) )

#Run BIC backward search
n=nrow(autos_train)
model1_bic = step(model1_start,k=log(n),trace = 0)
#size of selected model by backward BIC
length( coef(model1_bic) )
model1_bic

#checking model assumption
source("misc_functions.R")
diagnostics(model1_bic)

model1_selected=model1_bic

```

Clearly, this is not a good model. Fitted Residuals and Q-Q Plots indicated some sort variable tranformations are needed.

## 2.2  Method 2 - With variable transformations

We will take a 2-phases approach to finding a good model:

- Phase I - the Continuous variables phase 
- Pahse II - Adding categorical variables the 


### 2.2.1 - Phase 1: working with continous variable to determine the best model form for continous columns

#### 2.2.1.1 - break data-set into subgroups by fixing factor variable values

```{r}
#listing out all factor columns
columns_factor

autos_factor_groups=autos %>% count (abtest,vehicleType,gearbox,model,brand,fuelType,notRepairedDamage)
autos_factor_groups=autos_factor_groups[order(autos_factor_groups$n,decreasing = TRUE),]

#structure of autos_factor_groups
head(autos_factor_groups)

#Total number of groups
nrow(autos_factor_groups)

#Number of groups with more than 300 records
sum(autos_factor_groups$n>300)
```


#### 2.2.1.2 - work throght one subgroup first. (choose group 2)
```{r}
#choose group
selected_group_idx=2
group1=autos_factor_groups[selected_group_idx, ]
(group1.size = group1$n)
group1=subset(group1, select = -c(n) )

#get the records for the selected group
autos_1=autos
cols=names(group1)
for (i in 1:ncol(group1)){
  idx = autos_1[,cols[i]]==group1[[i]]
  autos_1=autos_1[idx,]
}
autos_1=subset(autos_1, select = columns_numeric )

```

todo: pairs(autos_1,col="dodgerblue"), and explain the reason we isolated the group

We will use the newly isolated dataset, **autos_1** to better help finding a model form for continuous variables

#### 2.2.1.3 - Try an additive model using all continous variables

```{r}
par(mfrow=c(1,2))
model2_add = lm(price ~ powerPS + kilometer+yearOfRegistration , data = autos_1)
diagnostics(model2_add)
```

The plots and test pValue indicates signifant voiloation of equal variance and normality assumption. We will try Box-Cox transformation on Price next.


#### 2.2.1.4 - Try Box-Cox tranformation on the selected group


```{r}
library(MASS)
library(lmtest)
par(mfrow=c(1,1))
boxcox_input_formula= as.formula ( as.character(model2_add$call[2]) )
out=boxcox(model2_add, plotit = TRUE, lambda = seq(-0.5, 1.0, by = 0.05))
( lambda=out$x[which.max(out$y)] )
model2_add_cox = lm( ((price^lambda-1)/lambda) ~ powerPS + kilometer+yearOfRegistration , data = autos_1 )
diagnostics(model2_add_cox)
```

Plots looks better but it seems additional predictor transformation might help.

#### 2.2.1.5 - finding predictor tranformation via backward BIC search

```{r}
# starting with log and 2nd order terms for all predictors
model2a_bic_start=lm( (price^lambda-1)/lambda ~ powerPS+yearOfRegistration+I(powerPS^2) + I(kilometer^2), data = autos_1 )
  
model2a_bic = step(model2a_bic_start,trace=0)
diagnostics(model2a_bic)
summary(model2a_bic)

#Save model2a for later steps
model2a=model2a_bic
formula_str=as.character(model2a$call[2])
```

#### 2.2.1.6 - Run box-cox tranformation all for groups with > 300 records

We will run box-cox transformation on subgroup of data that has more than 300 records..

```{r}
source("misc_functions.R")
boxcox_input_formula= as.formula ( as.character(model2_add$call[2]) )
(boxcox_lambda=subset_autodata_with_boxcox(autos,boxcox_input_formula))
hist(boxcox_lambda,breaks=20,col="lightblue")
lambda=mean(boxcox_lambda)
lambda
```
Based on our analysis above, we will use $\lambda=`r lambda`$ for the Box-Cox transformation!

### 2.2.2 - Phase 2: adding categorical variables to the model that was determined in Phase 1

The best model form with only continous variable is:  

- `r formula_str`  
- Where $\lambda=`r lambda`$

Next, we will add all factor varibles to the formula format we obtained from the Phase 1 as the starting model in backward BIC search.
  
#### 2.2.2.1 Searching for a good model using backward BIC   
```{r}
size_train=2000
idx_train=sample(1:nrow(autos),size_train)
autos_train=autos[idx_train,]
autos_train[,columns_factor]=lapply(autos_train[,columns_factor], as.factor)

model2_start = lm( ((price^lambda - 1)/lambda) ~ .-brand-vehicleType +  I(powerPS^2) + I(kilometer^2) + I(log(kilometer)), data=autos_train ) 
n=nrow(autos_train)
model2_selected_bic = step(model2_start,k=log(n),trace=0)
summary(model2_selected_bic)

diagnostics(model2_selected_bic)
```


####  2.2.2.2 Remove high influence data and refit the Phase 2 model

```{r}
fix_model=remove_high_influential_points_and_refit_model(model2_selected_bic, autos_train)
model2_selected=fix_model$new.model
fix_model
summary(model2_selected)
```

calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

## 2.3  Method 3 - find an interaction model based on method 2 (optional)
We will do this if we have time

# 3. Results
```{r}
#we have two models to compare results

summary(model1_selected)
summary(model2_selected)


```


# 4. Discussion

# 5. Appendix




